{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dd7934-d251-46aa-b361-800e7960fed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import gymnasium as gym\n",
    "from jaxtyping import Float32, Int8, Int32, PyTree\n",
    "from jaxtyping import PRNGKeyArray, Array\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c7dde5-a417-484b-a43a-866ea073ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(eqx.Module):\n",
    "    layers: list\n",
    "    def __init__(self, state_dim: int, key: PRNGKeyArray):\n",
    "        super().__init__()\n",
    "        subkey1, subkey2 = jax.random.split(key)\n",
    "        \n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(state_dim, 32, key=subkey1),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(32, 1, key=subkey2)\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, state: Float32[jnp.ndarray, \"state_dim\"]):\n",
    "        for layer in self.layers:\n",
    "            state = layer(state)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d72ac35-ef1b-4997-8770-e7f7c2d44ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Actor(eqx.Module):\n",
    "    layers: list\n",
    "    def __init__(self, state_dim: int, action_dim: int, key: PRNGKeyArray):\n",
    "        super().__init__()\n",
    "        subkey1, subkey2 = jax.random.split(key)\n",
    "        \n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(state_dim, 32, key=subkey1),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(32, action_dim, key=subkey2)\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, state: Float32[jnp.ndarray, \"state_dim\"]):\n",
    "        for layer in self.layers:\n",
    "            state = layer(state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea581aef-cf57-425b-9cc2-c2ce3e2e8c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_advantages(rewards: Float32[Array, \"batch_size max_steps\"],\n",
    "                        states: Float32[Array, \"batch_size state_dim max_steps\"],\n",
    "                        next_states: Float32[Array, \"batch_size state_dim max_steps\"],\n",
    "                        dones: Int8[Array, \"batch_size max_steps\"],\n",
    "                        critic: PyTree,\n",
    "                        gamma=0.99,\n",
    "                        lambda_=0.95):\n",
    "    values = jax.vmap(critic)(states)\n",
    "    next_values = jax.vmap(critic)(next_states)\n",
    "    \n",
    "    td_errors = rewards + gamma * next_values * (1 - dones) - values\n",
    "    \n",
    "    advantages = jnp.zeros_like(td_errors)\n",
    "    advantages.at[-1].set(td_errors[-1])\n",
    "    \n",
    "    for t in reversed(range(len(td_errors) - 1)):\n",
    "        a = td_errors[t] + gamma * lambda_ * advantages[t+1]\n",
    "        advantages = advantages.at[t].set(a)\n",
    "    \n",
    "    return advantages\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502e3869-6aff-4279-a101-f98ce1a4a217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_action(logits: Float32[Array, \"action_dim\"], key: PRNGKeyArray):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    probabilities = tfp.distributions.Categorical(logits=logits)\n",
    "    sampled_action = probabilities.sample(seed=subkey)\n",
    "    \n",
    "    return sampled_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622874ac-5961-422b-9261-cd7d58a7a552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_log_probs(policy: PyTree, state: Float32[Array, \"state_dim\"], action: int):\n",
    "    logits = policy(state)\n",
    "    action_probs = jax.nn.softmax(logits)   \n",
    "    log_probs = jnp.log(action_probs)\n",
    "    \n",
    "    return log_probs[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6992e60f-5cc2-4786-97d5-25c7a6b775fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dim=8, action_dim=4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "print(f\"{state_dim=}, {action_dim=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a62b2d-f2d0-4cfb-a615-6d44646d8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n",
    "key, subkey = jax.random.split(key)\n",
    "critic = Critic(state_dim, key=key)\n",
    "actor = Actor(state_dim, action_dim, key=subkey) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d8897d5-c6fe-4226-8248-32ce8a09ef38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rollout(env: gym.Env, key: PRNGKeyArray, actor: PyTree) -> Tuple[Float32[Array, \"eps_steps state_dim\"], \n",
    "                                                                    Float32[Array, \"eps_steps\"],\n",
    "                                                                    Float32[Array, \"eps_steps\"],\n",
    "                                                                    Float32[Array, \"eps_steps\"]]:\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    \n",
    "    # Run one episode\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # Store episode data\n",
    "    observations = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    dones = []\n",
    "    \n",
    "    while True:\n",
    "        key, subkey = jax.random.split(key)\n",
    "        logits = actor(obs)\n",
    "        action = int(get_action(logits, subkey))\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        observations.append(obs)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        \n",
    "        \n",
    "        if terminated or truncated:\n",
    "            dones.append(1)\n",
    "            break\n",
    "        \n",
    "        dones.append(0)\n",
    "        \n",
    "    return jnp.array(observations), jnp.array(rewards), jnp.array(actions), jnp.array(dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a41b4a5d-c5f6-4e72-b166-3666b1b240d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "observations, rewards, actions, dones = rollout(env, subkey, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fe9b7-bf73-43c3-94c9-d834c093191c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
